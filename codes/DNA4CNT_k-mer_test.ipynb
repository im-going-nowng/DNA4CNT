{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4010956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f61e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import utils as np_utils\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe94e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16011b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(seed):\n",
    "    random.seed(seed) \n",
    "    np.random.seed(seed) \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_CUDNN_USE_FRONTEND '] = '1'\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825b901",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a4b4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_random(fn, sample=True):\n",
    "    \n",
    "    #negative set\n",
    "    df0 = pd.read_csv('../random2.out', header=None, names=['seq'])\n",
    "    df0['label'] = 0\n",
    "    \n",
    "    #positive set\n",
    "    df1 = pd.read_csv(fn, header=None, names=['seq','cnt'])\n",
    "    df1['label'] = 1\n",
    "    \n",
    "    if sample==True:\n",
    "        df1=df1.sample(frac=1, random_state=seed_num).reset_index(drop=True)\n",
    "        df0=df0.sample(frac=1, random_state=seed_num).reset_index(drop=True)\n",
    "        df1.drop('cnt', axis=1, inplace=True)\n",
    "        df = pd.concat([df1[:10000], df0[:10000]])\n",
    "    else:\n",
    "        #cnt가 3 이상인 데이터만 추출\n",
    "        df1 = df1[df1.cnt>=3]\n",
    "        \n",
    "        # Train, Test set에 cnt값은 필요 없기 때문에 제거\n",
    "        df1.drop('cnt', axis=1, inplace=True)\n",
    "\n",
    "        # [:sample_size]\n",
    "        df = pd.concat([df1[:10000], df0[:10000]])\n",
    "        \n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1aeb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bases=['A','C','G','T']\n",
    "\n",
    "def dnatoidx(k):\n",
    "\n",
    "    dtoi = {}\n",
    "    kmers=[''.join(p) for p in itertools.product(bases, repeat=k)]\n",
    "    idx = 0\n",
    "    for kmer in kmers:\n",
    "        dtoi[kmer]=idx\n",
    "        idx += 1\n",
    "    return dtoi\n",
    "\n",
    "def count_kmer(seq, dtoi, k):\n",
    "    kmercnt = [0]*len(dtoi)\n",
    "    for i in range(30-k+1):\n",
    "        kmer = seq[i:i+k]\n",
    "        kmercnt[dtoi[kmer]] += 1\n",
    "    return kmercnt\n",
    "\n",
    "def count_starkmer(seq, dtoi, k, blank):\n",
    "    kmercnt = [0]*len(dtoi)\n",
    "    for i in range(len(seq)-(k+blank)+1):\n",
    "        kmer = seq[i]+seq[i+k+blank-1]\n",
    "#         print(i, kmer)\n",
    "        kmercnt[dtoi[kmer]] += 1\n",
    "    return kmercnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75360606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdb5dd91",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b0e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_model(k):\n",
    "    reset_seed(seed_num)\n",
    "    MLP_model = Sequential([\n",
    "        Dense(100, activation='relu',input_shape=(4**k,)),\n",
    "        Dropout(0.1, seed=seed_num),\n",
    "        Dense(30, activation='relu'),\n",
    "        Dropout(0.1, seed=seed_num),\n",
    "        Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "    MLP_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy','AUC'])\n",
    "    return MLP_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d04b6",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca61c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    encoded_list = []\n",
    "\n",
    "    def encode_seq(s):\n",
    "        Encode = {'A':[1,0,0,0],'T':[0,1,0,0],'C':[0,0,1,0],'G':[0,0,0,1], 'N':[0,0,0,0]}\n",
    "        return [Encode[x] for x in s]\n",
    "\n",
    "    for i in df.seq:\n",
    "        x = encode_seq(i)\n",
    "        encoded_list.append(x)\n",
    "\n",
    "    X = np.array(encoded_list)\n",
    "    X = X.astype('float32')\n",
    "    X.shape\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195580f",
   "metadata": {},
   "source": [
    "# Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c619f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df,seed):\n",
    "    dataX= preprocessing(df)\n",
    "    dataY=df.label\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(dataX,dataY,test_size=0.2,random_state=seed)\n",
    "\n",
    "    Y_train = keras.utils.np_utils.to_categorical(Y_train)\n",
    "    Y_test = keras.utils.np_utils.to_categorical(Y_test)\n",
    "\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04aa700",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b8dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(name,history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{name} loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f4f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_test, Y_test,verbose=0):\n",
    "    test_prediction = model.predict(X_test,verbose = 0)\n",
    "    prediction = np.argmax(test_prediction, axis=1)\n",
    "    prediction2 = test_prediction.T[1].T\n",
    "    answer = np.argmax(Y_test, axis=1)\n",
    "    confusion = confusion_matrix(answer, prediction)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(answer, prediction)\n",
    "    \n",
    "    \n",
    "    auc  = roc_auc_score(answer, prediction2)\n",
    "    \n",
    "    \n",
    "    pre = precision_score(answer, prediction)\n",
    "    \n",
    "\n",
    "    recall = recall_score(answer, prediction)\n",
    "    \n",
    "\n",
    "    specificity = confusion[0,0]/(confusion[0,1]+confusion[0,0])\n",
    "    \n",
    "\n",
    "    f1 = f1_score(answer, prediction)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('\\nTest confusion matrix :')\n",
    "        print(pd.DataFrame(confusion))\n",
    "        print('\\nTest Accuracy score: ',acc)\n",
    "        print('Test AUC score: ', auc)\n",
    "        print('Test Precision score: ', pre)\n",
    "        print('Test Recall score: ', recall)\n",
    "        print('Test Specificity score: ', specificity)\n",
    "        print('Test F1_score: ', f1,'\\n')\n",
    "    \n",
    "    return acc , auc, pre, recall, specificity, f1, answer, prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6deea6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_evaluation(model, X_test, Y_test,verbose=0):\n",
    "    prediction=model.predict(X_test)\n",
    "    prediction2=model.predict_proba(X_test).T[1].T\n",
    "    \n",
    "    answer = np.argmax(Y_test, axis=1)\n",
    "    confusion = confusion_matrix(answer, prediction)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(answer, prediction)\n",
    "    \n",
    "    \n",
    "    auc  = roc_auc_score(answer, prediction2)\n",
    "    \n",
    "    \n",
    "    pre = precision_score(answer, prediction)\n",
    "    \n",
    "\n",
    "    recall = recall_score(answer, prediction)\n",
    "    \n",
    "\n",
    "    specificity = confusion[0,0]/(confusion[0,1]+confusion[0,0])\n",
    "    \n",
    "\n",
    "    f1 = f1_score(answer, prediction)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('\\nTest confusion matrix :')\n",
    "        print(pd.DataFrame(confusion))\n",
    "        print('\\nTest Accuracy score: ',acc)\n",
    "        print('Test AUC score: ', auc)\n",
    "        print('Test Precision score: ', pre)\n",
    "        print('Test Recall score: ', recall)\n",
    "        print('Test Specificity score: ', specificity)\n",
    "        print('Test F1_score: ', f1,'\\n')\n",
    "    \n",
    "    return acc , auc, pre, recall, specificity, f1, answer, prediction2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd79ce",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc77e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_kmer_train(data,df,seed):\n",
    "    reset_seed(seed_num)\n",
    "    \n",
    "    call_back = tf.keras.callbacks.ModelCheckpoint(\n",
    "                f'R{r}_MLP_{k}_mer_{itr}.h5', monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                save_weights_only=False, mode='auto', save_freq='epoch', options=None\n",
    "                )\n",
    "\n",
    "    MLP=MLP_model(k)\n",
    "    history = MLP.fit(data[0], data[1], batch_size = 1024, \n",
    "                                epochs=epochs, validation_data=(data[2],data[3]), \n",
    "                                shuffle=True,callbacks=[call_back],\n",
    "                                verbose = 0)\n",
    "    \n",
    "    make_plot(f'mlp_{k}-mer',history)\n",
    "    best_model = tf.keras.models.load_model(f'R{r}_MLP_{k}_mer_{itr}.h5')\n",
    "    \n",
    "    acc , auc, pre, recall, specificity, f1,answer,pred = model_evaluation(best_model, data[4],data[5],verbose = 1)\n",
    "    \n",
    "    df.loc[len(df)] = [f'mlp-{k}mer',r,0 , acc , auc, pre, recall, f1]\n",
    "\n",
    "    \n",
    "    return best_model, df, answer, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f830920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_kmer_train(data,df,seed):\n",
    "    reset_seed(seed_num)\n",
    "    RF=RandomForestClassifier(random_state=itr)\n",
    "    RF.fit(X_train,y_train)\n",
    "    acc , auc, pre, recall, specificity, f1,answer,pred = RF_evaluation(RF, data[4],data[5],verbose = 1)\n",
    "    df.loc[len(df)] = [f'RF-{k}mer',r,0 , acc , auc, pre, recall, f1]\n",
    "    joblib.dump(RF,f'./R{r}_RF_{k}mer_{itr}.pkl')\n",
    "    return RF, df, answer, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27daf2a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "kmer_df = pd.DataFrame(columns=[\"model\",\"round\",\"shuffle\",\"acc\",\"auc\",\"pre\",\"recall\",\"f1\"])\n",
    "\n",
    "for k in [1,2,3,4,5]:\n",
    "\n",
    "\n",
    "    print(k)\n",
    "    scores = defaultdict(list)\n",
    "    dtoi = dnatoidx(k)\n",
    "    n_seq = 10000\n",
    "\n",
    "    for r in [3,4,5,6]:\n",
    "        df = getdata_random(f'../data/R{r}_1.out_N_unique', False)\n",
    "\n",
    "        cntfeature = []\n",
    "        for seq in df.seq:\n",
    "            cntfeature.append( count_kmer(seq, dtoi, k) )\n",
    "            \n",
    "        X = np.array(cntfeature)\n",
    "        y = df.label\n",
    "\n",
    "        for itr in range(10):\n",
    "            seed_num = itr\n",
    "            reset_seed(seed_num)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,random_state=seed_num)\n",
    "            X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5,random_state=seed_num)\n",
    "\n",
    "            y_train2 = keras.utils.np_utils.to_categorical(y_train)\n",
    "            y_valid2 = keras.utils.np_utils.to_categorical(y_valid)\n",
    "            y_test2 = keras.utils.np_utils.to_categorical(y_test) \n",
    "            \n",
    "            data = [X_train,y_train2,X_valid,y_valid2,X_test,y_test2]\n",
    "            \n",
    "            reset_seed(seed_num)\n",
    "            model ,kmer_df,_,_ = MLP_kmer_train(data,kmer_df,seed_num)\n",
    "            reset_seed(seed_num)\n",
    "            model ,kmer_df,_,_ = RF_kmer_train(data,kmer_df,seed)\n",
    "        print(kmer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ec238df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>round</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>pre</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp-1mer</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67250</td>\n",
       "      <td>0.734149</td>\n",
       "      <td>0.655686</td>\n",
       "      <td>0.726500</td>\n",
       "      <td>0.689279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF-1mer</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65100</td>\n",
       "      <td>0.693786</td>\n",
       "      <td>0.640074</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp-1mer</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65825</td>\n",
       "      <td>0.710449</td>\n",
       "      <td>0.647241</td>\n",
       "      <td>0.720747</td>\n",
       "      <td>0.682019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF-1mer</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62225</td>\n",
       "      <td>0.668306</td>\n",
       "      <td>0.628249</td>\n",
       "      <td>0.629794</td>\n",
       "      <td>0.629020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp-1mer</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.722533</td>\n",
       "      <td>0.644725</td>\n",
       "      <td>0.726995</td>\n",
       "      <td>0.683393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>RF-5mer</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80200</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>0.765736</td>\n",
       "      <td>0.844909</td>\n",
       "      <td>0.803376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>mlp-5mer</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85875</td>\n",
       "      <td>0.920777</td>\n",
       "      <td>0.846483</td>\n",
       "      <td>0.880376</td>\n",
       "      <td>0.863097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>RF-5mer</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81225</td>\n",
       "      <td>0.889381</td>\n",
       "      <td>0.799717</td>\n",
       "      <td>0.838853</td>\n",
       "      <td>0.818818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>mlp-5mer</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84875</td>\n",
       "      <td>0.914672</td>\n",
       "      <td>0.839086</td>\n",
       "      <td>0.851623</td>\n",
       "      <td>0.845308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>RF-5mer</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80550</td>\n",
       "      <td>0.886820</td>\n",
       "      <td>0.779165</td>\n",
       "      <td>0.836167</td>\n",
       "      <td>0.806660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  round  shuffle      acc       auc       pre    recall        f1\n",
       "0    mlp-1mer      3        0  0.67250  0.734149  0.655686  0.726500  0.689279\n",
       "1     RF-1mer      3        0  0.65100  0.693786  0.640074  0.690000  0.664100\n",
       "2    mlp-1mer      3        0  0.65825  0.710449  0.647241  0.720747  0.682019\n",
       "3     RF-1mer      3        0  0.62225  0.668306  0.628249  0.629794  0.629020\n",
       "4    mlp-1mer      3        0  0.66875  0.722533  0.644725  0.726995  0.683393\n",
       "..        ...    ...      ...      ...       ...       ...       ...       ...\n",
       "395   RF-5mer      6        0  0.80200  0.882307  0.765736  0.844909  0.803376\n",
       "396  mlp-5mer      6        0  0.85875  0.920777  0.846483  0.880376  0.863097\n",
       "397   RF-5mer      6        0  0.81225  0.889381  0.799717  0.838853  0.818818\n",
       "398  mlp-5mer      6        0  0.84875  0.914672  0.839086  0.851623  0.845308\n",
       "399   RF-5mer      6        0  0.80550  0.886820  0.779165  0.836167  0.806660\n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58b30146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmer_df.to_csv('k-mer_all.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
